# Communication Game on CIFAR-100
This directory contains the code for training and testing the Translation-Interpretation (TI) module in communication games between Speaker and Listener agents on the CIFAR-100 dataset.

## Overview

The Communication Game module implements a system where two neural agents (Speaker and Listener) learn to communicate through symbolic representations. The TI module serves as a translator that learns to map symbols from the Speaker agent to symbols understood by the Listener agent.

## Terminology Mapping

To help readers connect the concepts from the paper to the code implementation, here is a brief mapping:

| Paper Term                    | Code Implementation                                      |
| :---------------------------- | :------------------------------------------------------- |
| Translation-Interpretation Module | `TImodule` in `Translators.py`                     |
| Speaker Agent                 | CATS-Net model (`Net2` in `SEAnet.py`) that learned all 100 categories |
| Listener Agent               | CATS-Net model (`Net2` in `SEAnet.py`) that has learned 99 categories and processes translated concept vector |
| Concept (or symbol) Translation           | Process of converting Speaker symbols to Listener-compatible format |
| Context Vectors              | Symbolic representations (`contexts`) used by agents    |
| Communication Round          | Training iteration with specific leave-one-out sets            |

## Prerequisites

- Python 3.11.11
- PyTorch 2.4.0
- CUDA 11.8
- Torchvision 0.19.0
- NumPy 1.26.4
- SciPy 1.14.0
- Matplotlib (for visualization)
- An environment with CUDA enabled GPUs is recommended. Set the desired GPU using `os.environ["CUDA_VISIBLE_DEVICES"] = "0"` in the code.

## Directory Structure

- `C01_Comm_CIFAR100_main_train.py`: Main training script for the TI module.
- `C02_Comm_CIFAR100_main_test.py`: Testing script for evaluating trained TI modules.
- `Symbols_of_Speaker/`: Directory containing symbol sets generated by the Speaker agent.
  - `context_r_X_e_999.mat`: Speaker symbols for round X at epoch 999.
- `Testing_Symbols_of_Speaker/`: Directory containing test symbol sets from Speaker agent.
  - `context_ep_1999.mat`: Test symbols at epoch 1999.
- `Symbol_and_Model_of_Listener/`: Directory containing Listener agent assets.
  - `contexts/`: Saved context vectors of the Listener agent.
  - `checkpoint/`: Saved model checkpoints of the Listener agent.
- `datafile/`: Directory for additional data files.
- `YYYY-MM-DD/`: Output directories created based on run date.
  - `checkpoint/`: Saved TI module checkpoints.
  - `contexts/`: Translated symbol predictions.
  - `train_loss.log`: Training loss logs.
  - `symbol_translation.log`: Symbol translation logs.
  - `test_acc.log`: Testing accuracy logs.
  - `evaluation_results.log`: Final evaluation results (test phase).

## Training

To train the TI module, run the training script:

```bash
python C01_Comm_CIFAR100_main_train.py [arguments]
```

**Key Arguments:**

- `--device`: Device type (`cuda` or `cpu`, default: `cuda`)
- `--worker`: Number of workers for data loader (default: 1)
- `--ct_batch_size_train`: Batch size of symbols in D_99 when training TI module (default: 96)
- `--batch_size_test`: Batch size for testing dataset (default: 100)
- `--num_class`: Number of total classes (default: 100)
- `--class_id_unaligned`: List of unaligned class IDs during TI training (default: range(1,100))
- `--start_epoch`: Starting epoch number (default: 0)
- `--end_epoch`: Ending epoch number (default: 102)
- `--context_dim`: Context dimension (default: 20)
- `--TInet_hidden_layers`: Number of hidden layers in TI module (default: 10)
- `--TInet_hidden_neurons`: Number of neurons per hidden layer (default: 500)
- `--TInet_p`: Dropout probability for TI module (default: 0.3)
- `--learning_rate`: Learning rate for TI module (default: 0.0001)
- `--lr_sche_gamma`: Learning rate decay factor (default: 0.5)
- `--lr_sche_steps`: Learning rate decay period (default: 10)

**Example Usage:**

```bash
# Training with default parameters
python C01_Comm_CIFAR100_main_train.py
```

## Testing

To test trained TI modules, run the testing script:

```bash
python C02_Comm_CIFAR100_main_test.py [arguments]
```

The testing script uses the same arguments as the training script but loads pre-trained models for evaluation.

**Example Usage:**

```bash
# Testing all 100 teacher-student pairs
python C02_Comm_CIFAR100_main_test.py
```

## Model Architecture

The Communication Game system consists of:

1. **TI Module**: Multi-layer perceptron that translates Speaker symbols to Listener symbols
   - Input: Speaker context vectors (dimension: `context_dim`)
   - Output: Translated context vectors compatible with Listener
   - Architecture: Configurable hidden layers with dropout regularization

2. **Speaker Agent**: Generates symbolic representations for CIFAR-100 classes
   - Produces context vectors for each class and communication round

3. **Listener Agent**: CATS-Net model that processes translated symbols
   - Uses pre-trained ResNet18 feature extractor
   - Evaluates classification accuracy on positive/negative samples

## Training Process

The training process involves:

1. **Symbol Loading**: Load Speaker symbols from different communication rounds
2. **Target Preparation**: Use Listener symbols as translation targets
3. **TI Training**: Train the translation module using MSE loss
4. **Symbol Translation**: Periodically translate test symbols
5. **Accuracy Evaluation**: Test translated symbols on Listener agent
6. **Model Selection**: Save best-performing models based on accuracy

### Training Loop Details:
- For each epoch, randomly sample communication rounds for training
- Load corresponding Speaker symbols and target Listener symbols
- Train TI module to minimize translation error
- Every 2 epochs, evaluate translation quality on test symbols
- Save best model based on combined positive/negative accuracy

## Testing Process

The testing process includes:

1. **Model Loading**: Load trained TI modules for each test class
2. **Symbol Translation**: Translate Speaker test symbols to Listener format
3. **Accuracy Evaluation**: Test translated symbols on Listener models
4. **Statistical Analysis**: Perform statistical significance tests
5. **Results Logging**: Save detailed evaluation results

## Output Files

### Training Phase:
- **TI Module Checkpoints**: Complete model state and parameters
- **Translated Symbols**: Predicted context vectors at different checkpoints
- **Training Logs**: Loss progression and accuracy metrics
- **Symbol Translation Logs**: Detailed translation outputs

### Testing Phase:
- **Evaluation Results**: Comprehensive accuracy analysis
- **Statistical Tests**: Significance testing results
- **Summary Statistics**: Overall performance metrics

### Accuracy Data for Plot:
- Saved in `../../Results/single_ct_acc.csv` column named `best_acc_2`

## Performance Metrics

The system evaluates performance using:

1. **Positive Accuracy**: Classification accuracy on correct class-symbol pairs
2. **Negative Accuracy**: Classification accuracy on incorrect class-symbol pairs
3. **Combined Accuracy**: Average of positive and negative accuracies
4. **Statistical Significance**: One-sample t-tests against performance thresholds

## Notes

- The system requires pre-trained Speaker symbols and Listener models
- Training alternates between symbol translation and accuracy evaluation
- Best models are selected based on combined positive/negative accuracy
- GPU usage is controlled via `CUDA_VISIBLE_DEVICES` environment variable
- Statistical analysis includes significance testing at Î± = 0.05 level
- Results are automatically timestamped and organized by date
- The system supports batch processing of multiple unaligned classes
- Communication rounds represent different symbol generation iterations 