
@article{hebart_things_2019,
	title = {{THINGS}: {A} database of 1,854 object concepts and more than 26,000 naturalistic object images},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {{THINGS}},
	abstract = {In recent years, the use of a large number of object concepts and naturalistic object images has been growing strongly in cognitive neuroscience research. Classical databases of object concepts are based mostly on a manually curated set of concepts. Further, databases of naturalistic object images typically consist of single images of objects cropped from their background, or a large number of naturalistic images of varying quality, requiring elaborate manual image curation. Here we provide a set of 1,854 diverse object concepts sampled systematically from concrete picturable and nameable nouns in the American English language. Using these object concepts, we conducted a large-scale web image search to compile a database of 26,107 high-quality naturalistic images of those objects, with 12 or more object images per concept and all images cropped to square size. Using crowdsourcing, we provide higher-level category membership for the 27 most common categories and validate them by relating them to representations in a semantic embedding derived from large text corpora. Finally, by feeding images through a deep convolutional neural network, we demonstrate that they exhibit high selectivity for different object concepts, while at the same time preserving variability of different object images within each concept. Together, the THINGS database provides a rich resource of object concepts and object images and offers a tool for both systematic and large-scale naturalistic research in the fields of psychology, neuroscience, and computer science.},
	language = {en},
	number = {10},
	urldate = {2025-09-21},
	journal = {PLOS ONE},
	author = {Hebart, Martin N. and Dickter, Adam H. and Kidder, Alexis and Kwok, Wan Y. and Corriveau, Anna and Wicklin, Caitlin Van and Baker, Chris I.},
	month = oct,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Computational neuroscience, Computer and information sciences, Computer imaging, Graphical user interfaces, Neural networks, Semantics, Vision, Visual object recognition},
	pages = {e0223792},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\DVX48H5P\\Hebart et al. - 2019 - THINGS A database of 1,854 object concepts and more than 26,000 naturalistic object images.pdf:application/pdf},
}

@article{carandini_normalization_2012,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	copyright = {2011 Springer Nature Limited},
	issn = {1471-0048},
	url = {},
	doi = {},
	abstract = {Normalization computes a ratio between the response of an individual neuron and the summed activity of a pool of neurons.The normalization model was developed to explain responses in the primary visual cortex (V1), and has been seen to operate in a variety of other regions of the visual system: light adaptation in the retina, contrast normalization in the retina and lateral geniculate nucleus, and visual processing in higher visual cortical areas beyond V1.Normalization has also been proposed to be at the root of the modulatory effects of visual attention on neural responses in the visual cortex.Normalization is seen in multiple species and brain regions. These include olfactory processing and representation in the fruitfly antennal lobe, the encoding of value in the posterior parietal cortex, multisensory integration of visual motion and vestibular signals, and auditory processing in the primary auditory cortex.Different (feedforward and feedback) neural circuits and mechanisms might perform normalization, including presynaptic inhibition, shunting inhibition, synaptic depression, changes in the amplitude of ongoing activity and balanced amplification.The effects of normalization can be measured behaviourally.The computational benefits of normalization include maximizing sensitivity, providing invariance with respect to some stimulus dimensions at the expense of others, facilitating the decoding of a distributed neural representation, facilitating the discrimination among representations of different stimuli, providing max-pooling (winner-take-all competition) and reducing redundancy.Understanding canonical neural computations such as normalization may shed light on psychiatric, neurological and developmental disorders.},
	language = {en},
	number = {1},
	urldate = {2025-05-07},
	journal = {Nat Rev Neurosci},
	author = {Carandini, Matteo and Heeger, David J.},
	month = jan,
	year = {2012},
	note = {},
	keywords = {Computational neuroscience, Neuronal physiology, Sensory systems},
	pages = {51--62},
	file = {已接受版本:/Users/lxguo/Zotero/storage/TF2LSM3E/Carandini和Heeger - 2012 - Normalization as a canonical neural computation.pdf:application/pdf},
}

@article{fu_different_2022,
	title = {Different computational relations in language are captured by distinct brain systems},
	volume = {33},
	issn = {1047-3211},
	url = {},
	doi = {},
	abstract = {A critical way for humans to acquire information is through language, yet whether and how language experience drives specific neural semantic representations is still poorly understood. We considered statistical properties captured by 3 different computational principles of language (simple co-occurrence, network-(graph)-topological relations, and neural-network-vector-embedding relations) and tested the extent to which they can explain the neural patterns of semantic representations, measured by 2 functional magnetic resonance imaging experiments that shared common semantic processes. Distinct graph-topological word relations, and not simple co-occurrence or neural-network-vector-embedding relations, had unique explanatory power for the neural patterns in the anterior temporal lobe (capturing graph-common-neighbors), inferior frontal gyrus, and posterior middle/inferior temporal gyrus (capturing graph-shortest-path). These results were relatively specific to language: they were not explained by sensory-motor similarities and the same computational relations of visual objects (based on visual image database) showed effects in the visual cortex in the picture naming experiment. That is, different topological properties within language and the same topological computations (common-neighbors) for language and visual inputs are captured by different brain regions. These findings reveal the specific neural semantic representations along graph-topological properties of language, highlighting the information type-specific and statistical property-specific manner of semantic representations in the human brain.},
	language = {en-US},
	number = {4},
	urldate = {},
	journal = {Cerebral Cortex},
	author = {Fu, Ze and Wang, Xiaosha and Wang, Xiaoying and Yang, Huichao and Wang, Jiahuan and Wei, Tao and Liao, Xuhong and Liu, Zhiyuan and Chen, Huimin and Bi, Yanchao},
	year = {2022},
	pages = {997--1013},
	file = {Fu et al. - 2022 - Different computational relations in language are .pdf:/Users/lxguo/Zotero/storage/V34LMBFP/Fu et al. - 2022 - Different computational relations in language are .pdf:application/pdf;Snapshot:/Users/lxguo/Zotero/storage/4CHQLF4S/6553592.html:text/html},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	urldate = {2021-12-14},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\SALDKZQ4\\Vaswani 等。 - 2017 - Attention is All you Need.pdf:application/pdf},
}

@inproceedings{radford_learning_2021,
	title = {Learning {Transferable} {Visual} {Models} {From} {Natural} {Language} {Supervision}},
	abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.},
	language = {en},
	urldate = {2022-10-13},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	month = jul,
	year = {2021},
	note = {},
	pages = {8748--8763},
	file = {2103.00020.pdf:E\:\\Zotero\\Personal\\storage\\CPTFHCRE\\2103.00020.pdf:application/pdf;Full Text PDF:E\:\\Zotero\\Personal\\storage\\CRMLD4LL\\Radford 等。 - 2021 - Learning Transferable Visual Models From Natural L.pdf:application/pdf;Supplementary PDF:E\:\\Zotero\\Personal\\storage\\7VESZI94\\Radford 等。 - 2021 - Learning Transferable Visual Models From Natural L.pdf:application/pdf},
}

@inproceedings{li_blip-2_2023,
	title = {{BLIP}-2: {Bootstrapping} {Language}-{Image} {Pre}-training with {Frozen} {Image} {Encoders} and {Large} {Language} {Models}},
	shorttitle = {{BLIP}-2},
	abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model’s emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
	language = {en},
	urldate = {2024-05-09},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {},
	author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
	month = jul,
	year = {2023},
	note = {},
	pages = {19730--19742},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\DZWKJPMU\\Li et al. - 2023 - BLIP-2 Bootstrapping Language-Image Pre-training .pdf:application/pdf},
}

@misc{wu_deepseek-vl2_2024,
	title = {{DeepSeek}-{VL2}: {Mixture}-of-{Experts} {Vision}-{Language} {Models} for {Advanced} {Multimodal} {Understanding}},
	shorttitle = {{DeepSeek}-{VL2}},
	abstract = {We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades. For the vision component, we incorporate a dynamic tiling vision encoding strategy designed for processing high-resolution images with different aspect ratios. For the language component, we leverage DeepSeekMoE models with the Multi-head Latent Attention mechanism, which compresses Key-Value cache into latent vectors, to enable efficient inference and high throughput. Trained on an improved vision-language dataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks, including but not limited to visual question answering, optical character recognition, document/table/chart understanding, and visual grounding. Our model series is composed of three variants: DeepSeek-VL2-Tiny, DeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated parameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art performance with similar or fewer activated parameters compared to existing open-source dense and MoE-based models. Codes and pre-trained models are publicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.},
	language = {en-US},
	urldate = {2025-02-13},
	publisher = {},
	author = {Wu, Zhiyu and Chen, Xiaokang and Pan, Zizheng and Liu, Xingchao and Liu, Wen and Dai, Damai and Gao, Huazuo and Ma, Yiyang and Wu, Chengyue and Wang, Bingxuan and Xie, Zhenda and Wu, Yu and Hu, Kai and Wang, Jiawei and Sun, Yaofeng and Li, Yukun and Piao, Yishi and Guan, Kang and Liu, Aixin and Xie, Xin and You, Yuxiang and Dong, Kai and Yu, Xingkai and Zhang, Haowei and Zhao, Liang and Wang, Yisong and Ruan, Chong},
	month = dec,
	year = {2024},
	note = {arXiv:2412.10302 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
	file = {Preprint PDF:E\:\\Zotero\\Personal\\storage\\NCI4TLK8\\Wu et al. - 2024 - DeepSeek-VL2 Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding.pdf:application/pdf;Snapshot:E\:\\Zotero\\Personal\\storage\\ZMGL9F36\\2412.html:text/html},
}

@misc{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2023-03-08},
	publisher = {},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv:2010.11929 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:E\:\\Zotero\\Personal\\storage\\HLLIX2TV\\Dosovitskiy 等 - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf:application/pdf;arXiv.org Snapshot:E\:\\Zotero\\Personal\\storage\\5CJZIBQQ\\2010.html:text/html},
}

@article{binder_neurobiology_2011,
	title = {The neurobiology of semantic memory},
	volume = {15},
	issn = {1364-6613, 1879-307X},
	language = {English},
	number = {11},
	urldate = {2025-02-28},
	journal = {Trends in Cognitive Sciences},
	author = {Binder, Jeffrey R. and Desai, Rutvik H.},
	month = nov,
	year = {2011},
	pmid = {22001867},
	note = {},
	pages = {527--536},
	file = {Accepted Version:E\:\\Zotero\\Personal\\storage\\6PLFTEEC\\Binder and Desai - 2011 - The neurobiology of semantic memory.pdf:application/pdf},
}

@article{grill-spector_functional_2014,
	title = {The functional architecture of the ventral temporal cortex and its role in categorization},
	volume = {15},
	copyright = {2014 Springer Nature Limited},
	issn = {1471-0048},
	abstract = {Understanding information processing in the visual system requires an understanding of the interplay among the system's computational goals and representations, and their physical implementation in the brain.Recent results indicate a consistent topology of functional representations relative to each other and anatomical landmarks in high-level visual cortex.The consistent topology of functional representations reveals that axes of representational spaces are physically implemented as axes in cortical space.Anatomical constraints might determine the topology of functional representations in the brain, which would explain the correspondence between representational and anatomical axes in the ventral temporal cortex (VTC).Superimposition and topology generate predictable spatial convergences and divergences among functional representations, which in turn enable information integration and parallel processing, respectively.Superimposition and topological organization in the VTC generates a series of nested functional representations, the arrangements of which generate a spatial hierarchy of category information.The spatial scale of functional representations may be tied to the level of category abstractness in which more abstract information is represented in larger spatial scales across the VTC.},
	language = {en},
	number = {8},
	urldate = {2025-02-28},
	journal = {Nat Rev Neurosci},
	author = {Grill-Spector, Kalanit and Weiner, Kevin S.},
	month = aug,
	year = {2014},
	note = {},
	keywords = {Extrastriate cortex, Object vision},
	pages = {536--548},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\5ZQVXLNS\\Grill-Spector and Weiner - 2014 - The functional architecture of the ventral temporal cortex and its role in categorization.pdf:application/pdf},
}

@article{haxby_common_2011,
	title = {A {Common}, {High}-{Dimensional} {Model} of the {Representational} {Space} in {Human} {Ventral} {Temporal} {Cortex}},
	volume = {72},
	issn = {0896-6273},
	language = {English},
	number = {2},
	urldate = {2025-02-28},
	journal = {Neuron},
	author = {Haxby, James V. and Guntupalli, J. Swaroop and Connolly, Andrew C. and Halchenko, Yaroslav O. and Conroy, Bryan R. and Gobbini, M. Ida and Hanke, Michael and Ramadge, Peter J.},
	month = oct,
	year = {2011},
	pmid = {22017997},
	note = {},
	pages = {404--416},
	file = {Accepted Version:E\:\\Zotero\\Personal\\storage\\3GRD7R2Z\\Haxby et al. - 2011 - A Common, High-Dimensional Model of the Representational Space in Human Ventral Temporal Cortex.pdf:application/pdf},
}

@article{hebart_revealing_2020,
	title = {Revealing the multidimensional mental representations of natural objects underlying human similarity judgements},
	volume = {4},
	copyright = {2020 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
	issn = {2397-3374},
	abstract = {Hebart et al. developed a computational model of similarity judgements for 1,854 natural objects. The model accurately predicted similarity and revealed 49 interpretable dimensions that reflect both perceptual and conceptual object properties.},
	language = {en},
	number = {11},
	urldate = {2024-11-28},
	journal = {Nat Hum Behav},
	author = {Hebart, Martin N. and Zheng, Charles Y. and Pereira, Francisco and Baker, Chris I.},
	month = nov,
	year = {2020},
	note = {},
	keywords = {Human behaviour, Perception, Computational models},
	pages = {1173--1185},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\8GN394LX\\Hebart et al. - 2020 - Revealing the multidimensional mental representations of natural objects underlying human similarity.pdf:application/pdf},
}

@article{mcrae_semantic_2005,
	title = {Semantic feature production norms for a large set of living and nonliving things},
	volume = {37},
	issn = {1554-3528},
	abstract = {Semantic features have provided insight into numerous behavioral phenomena concerning concepts, categorization, and semantic memory in adults, children, and neuropsychological populations. Numerous theories and models in these areas are based on representations and computations involving semantic features. Consequently, empirically derived semantic feature production norms have played, and continue to play, a highly useful role in these domains. This article describes a set of feature norms collected from approximately 725 participants for 541 living (dog) and nonliving (chair) basic-level concepts, the largest such set of norms developed to date. This article describes the norms and numerous statistics associated with them. Our aim is to make these norms available to facilitate other research, while obviating the need to repeat the labor-intensive methods involved in collecting and analyzing such norms. The full set of norms may be downloaded from www.psychonomic.org/archive.},
	language = {en},
	number = {4},
	urldate = {2025-02-28},
	journal = {Behavior Research Methods},
	author = {McRae, Ken and Cree, George S. and Seidenberg, Mark S. and Mcnorgan, Chris},
	month = nov,
	year = {2005},
	keywords = {Dyslexia, Feature Correlation, Feature Norm, Semantic Feature, Semantic Memory},
	pages = {547--559},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\64C36LSA\\McRae et al. - 2005 - Semantic feature production norms for a large set of living and nonliving things.pdf:application/pdf},
}

@article{devereux_centre_2014,
	title = {The {Centre} for {Speech}, {Language} and the {Brain} ({CSLB}) concept property norms},
	volume = {46},
	issn = {1554-3528},
	abstract = {Theories of the representation and processing of concepts have been greatly enhanced by models based on information available in semantic property norms. This information relates both to the identity of the features produced in the norms and to their statistical properties. In this article, we introduce a new and large set of property norms that are designed to be a more flexible tool to meet the demands of many different disciplines interested in conceptual knowledge representation, from cognitive psychology to computational linguistics. As well as providing all features listed by 2 or more participants, we also show the considerable linguistic variation that underlies each normalized feature label and the number of participants who generated each variant. Our norms are highly comparable with the largest extant set (McRae, Cree, Seidenberg, \& McNorgan, 2005) in terms of the number and distribution of features. In addition, we show how the norms give rise to a coherent category structure. We provide these norms in the hope that the greater detail available in the Centre for Speech, Language and the Brain norms should further promote the development of models of conceptual knowledge. The norms can be downloaded at www.csl.psychol.cam.ac.uk/propertynorms.},
	language = {en},
	number = {4},
	urldate = {2025-02-28},
	journal = {Behav Res},
	author = {Devereux, Barry J. and Tyler, Lorraine K. and Geertzen, Jeroen and Randall, Billi},
	month = dec,
	year = {2014},
	keywords = {Concepts, Property norms, Semantic features, Semantic similarity},
	pages = {1119--1127},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\FX4UXWTF\\Devereux et al. - 2014 - The Centre for Speech, Language and the Brain (CSLB) concept property norms.pdf:application/pdf},
}

@article{zeng_continual_2019,
	title = {Continual learning of context-dependent processing in neural networks},
	volume = {1},
	issn = {2522-5839},
	language = {en},
	number = {8},
	urldate = {2021-04-08},
	journal = {Nat Mach Intell},
	author = {Zeng, Guanxiong and Chen, Yang and Cui, Bo and Yu, Shan},
	year = {2019},
	pages = {364--372},
	file = {1810.01256_translated.pdf:E\:\\Zotero\\Personal\\storage\\XDKHFQHD\\1810.01256_translated.pdf:application/pdf;OWM_Supplementary information.pdf:E\:\\Zotero\\Personal\\storage\\CTIJSKBT\\OWM_Supplementary information.pdf:application/pdf;OWM.pdf:E\:\\Zotero\\Personal\\storage\\2IWEYLEN\\OWM.pdf:application/pdf},
}

@article{kriegeskorte_representational_2008,
	title = {Representational similarity analysis - connecting the branches of systems neuroscience},
	volume = {2},
	issn = {1662-5137},
	abstract = {A fundamental challenge for systems neuroscience is to quantitatively relate its three major branches of research: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g. single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement, and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices, which characterize the information carried by a given representation in a brain or model. We propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing representational dissimilarity matrices. We demonstrate RSA by relating representations of visual objects as measured with fMRI to computational models spanning a wide range of complexities. We argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
	language = {English},
	urldate = {2024-03-11},
	journal = {Front. Syst. Neurosci.},
	author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter A.},
	year = {2008},
	keywords = {computational modeling, Electrophysiology, fMRI, population code, representation, Similarity},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\GWF4LKPR\\Kriegeskorte et al. - 2008 - Representational similarity analysis - connecting .pdf:application/pdf},
}

@article{jackson_reverse-engineering_2021,
	title = {Reverse-engineering the cortical architecture for controlled semantic cognition},
	volume = {5},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2397-3374},
	abstract = {We employ a reverse-engineering approach to illuminate the neurocomputational building blocks that combine to support controlled semantic cognition: the storage and context-appropriate use of conceptual knowledge. By systematically varying the structure of a computational model and assessing the functional consequences, we identified the architectural properties that best promote some core functions of the semantic system. Semantic cognition presents a challenging test case, as the brain must achieve two seemingly contradictory functions: abstracting context-invariant conceptual representations across time and modalities, while producing specific context-sensitive behaviours appropriate for the immediate task. These functions were best achieved in models possessing a single, deep multimodal hub with sparse connections from modality-specific regions, and control systems acting on peripheral rather than deep network layers. The reverse-engineered model provides a unifying account of core findings in the cognitive neuroscience of controlled semantic cognition, including evidence from anatomy, neuropsychology and functional brain imaging.},
	language = {en},
	number = {6},
	urldate = {2024-03-19},
	journal = {Nat Hum Behav},
	author = {Jackson, Rebecca L. and Rogers, Timothy T. and Lambon Ralph, Matthew A.},
	year = {2021},
	keywords = {Cognitive control, Language},
	pages = {774--786},
	file = {41562_2020_1034_MOESM1_ESM.pdf:E\:\\Zotero\\Personal\\storage\\ZQJPVPSX\\41562_2020_1034_MOESM1_ESM.pdf:application/pdf;Full Text PDF:E\:\\Zotero\\Personal\\storage\\BEPA2DKX\\Jackson et al. - 2021 - Reverse-engineering the cortical architecture for .pdf:application/pdf},
}

@book{de1916course,
    address = {La Salle, Ill.},
    title={Course in general linguistics (Edited by Charles Bally and Albert Sechehaye)},
    publisher = {Open Court},
    author={De Saussure, Ferdinand},
    year={1916},
    doi = {}
}

@article{schacter_cognitive_2007,
	title = {The cognitive neuroscience of constructive memory: remembering the past and imagining the future},
	volume = {362},
	shorttitle = {The cognitive neuroscience of constructive memory},
	abstract = {Episodic memory is widely conceived as a fundamentally constructive, rather than reproductive, process that is prone to various kinds of errors and illusions. With a view towards examining the functions served by a constructive episodic memory system, we consider recent neuropsychological and neuroimaging studies indicating that some types of memory distortions reflect the operation of adaptive processes. An important function of a constructive episodic memory is to allow individuals to simulate or imagine future episodes, happenings and scenarios. Since the future is not an exact repetition of the past, simulation of future episodes requires a system that can draw on the past in a manner that flexibly extracts and recombines elements of previous experiences. Consistent with this constructive episodic simulation hypothesis, we consider cognitive, neuropsychological and neuroimaging evidence showing that there is considerable overlap in the psychological and neural processes involved in remembering the past and imagining the future.},
	number = {1481},
	urldate = {2025-04-01},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Schacter, Daniel L and Addis, Donna Rose},
	month = mar,
	year = {2007},
	note = {},
	keywords = {Alzheimer's disease, amnesia, constructive memory, false recognition, mental simulation, neuroimaging},
	pages = {773--786},
	file = {Full Text:E\:\\Zotero\\Personal\\storage\\R5ZX5A87\\Schacter and Addis - 2007 - The cognitive neuroscience of constructive memory remembering the past and imagining the future.pdf:application/pdf},
}


@book{carey_origin_2009,
	address = {New York, NY, US},
	series = {The origin of concepts},
	title = {The origin of concepts},
	isbn = {978-0-19-536763-8},
	abstract = {Only human beings have a rich conceptual repertoire with concepts like tort, entropy, Abelian group, mannerism, icon, and deconstruction. How have humans constructed these concepts? And once they have been constructed by adults, how do children acquire them? While primarily focusing on the second question, in The Origin of Concepts, Susan Carey shows that the answers to both overlap substantially. Carey begins by characterizing the innate starting point for conceptual development, namely systems of "core cognition." Representations of core cognition are the output of dedicated input analyzers, as with perceptual representations, but these core representations differ from perceptual representations in having more abstract contents and richer functional roles. Carey argues that the key to understanding cognitive development lies in recognizing conceptual discontinuities in which new representational systems emerge that have more expressive power than core cognition and are also incommensurate with core cognition and other earlier representational systems. Finally, Carey fleshes out Quinian bootstrapping, a learning mechanism that has been repeatedly sketched in the literature on the history and philosophy of science. She demonstrates that Quinian bootstrapping is a major mechanism in the construction of new representational resources over the course of children's cognitive development. Carey shows how developmental cognitive science resolves aspects of long-standing philosophical debates about the existence, nature, content, and format of innate knowledge. She also shows that understanding the processes of conceptual development in children illuminates the historical process by which concepts are constructed, and transforms the way we think about philosophical problems about the nature of concepts and the relations between language and thought. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Oxford University Press},
	author = {Carey, Susan},
	year = {2009},
	doi = {10.1093/acprof:oso/9780195367638.001.0001},
	note = {Pages: viii, 598},
	keywords = {Cognitive Development, Concepts, Language, Philosophies, Thinking},
	file = {Snapshot:E\:\\Zotero\\Personal\\storage\\CKCP4RJ7\\2009-05889-000.html:text/html},
}


@article{piantadosi_why_2024,
	title = {Why concepts are (probably) vectors},
	volume = {28},
	issn = {1364-6613, 1879-307X},
	abstract = {{\textless}h2{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}For decades, cognitive scientists have debated what kind of representation might characterize human concepts. Whatever the format of the representation, it must allow for the computation of varied properties, including similarities, features, categories, definitions, and relations. It must also support the development of theories, \textit{ad hoc} categories, and knowledge of procedures. Here, we discuss why vector-based representations provide a compelling account that can meet all these needs while being plausibly encoded into neural architectures. This view has become especially promising with recent advances in both large language models and vector symbolic architectures. These innovations show how vectors can handle many properties traditionally thought to be out of reach for neural models, including compositionality, definitions, structures, and symbolic computational processes.{\textless}/p{\textgreater}},
	language = {en-US},
	number = {9},
	urldate = {2024-11-11},
	journal = {Trends in Cognitive Sciences},
	author = {Piantadosi, Steven T. and Muller, Dyana C. Y. and Rule, Joshua S. and Kaushik, Karthikeya and Gorenstein, Mark and Leib, Elena R. and Sanford, Emily},
	month = sep,
	year = {2024},
	pmid = {39112125},
	note = {},
	pages = {844--856},
	file = {PDF:E\:\\Zotero\\Personal\\storage\\CIAYRHZ2\\Piantadosi et al. - 2024 - Why concepts are (probably) vectors.pdf:application/pdf},
}

@article{kiefer_conceptual_2012,
	series = {Language and the {Motor} {System}},
	title = {Conceptual representations in mind and brain: {Theoretical} developments, current evidence and future directions},
	volume = {48},
	issn = {0010-9452},
	shorttitle = {Conceptual representations in mind and brain},
	url = {},
	doi = {},
	abstract = {Conceptual representations in long-term memory crucially contribute to perception and action, language and thought. However, the precise nature of these conceptual memory traces is discussed controversially. In particular, the grounding of concepts in the sensory and motor brain systems is the focus of a current debate. Here, we review theoretical accounts of the structure and neural basis of conceptual memory and evaluate them in light of recent empirical evidence. Models of conceptual processing can be distinguished along four dimensions: (i) amodal versus modality-specific, (ii) localist versus distributed, (iii) innate versus experience-dependent, and (iv) stable versus flexible. A systematic review of behavioral and neuroimaging studies in healthy participants along with brain-damaged patients will then be used to evaluate the competing theoretical approaches to conceptual representations. These findings indicate that concepts are flexible, distributed representations comprised of modality-specific conceptual features. Conceptual features are stored in distinct sensory and motor brain areas depending on specific sensory and motor experiences during concept acquisition. Three important controversial issues are highlighted, which require further clarification in future research: the existence of an amodal conceptual representation in the anterior temporal lobe, the causal role of sensory and motor activation for conceptual processing and the grounding of abstract concepts in perception and action. We argue that an embodiment view of conceptual representations realized as distributed sensory and motor cell assemblies that are complemented by supramodal integration brain circuits may serve as a theoretical framework to guide future research on concrete and abstract concepts.},
	number = {7},
	urldate = {2025-03-29},
	journal = {Cortex},
	author = {Kiefer, Markus and Pulvermüller, Friedemann},
	month = jul,
	year = {2012},
	keywords = {Brain-damaged patients, Grounded cognition, Language, Neuroimaging, Semantic memory},
	pages = {805--825},
	file = {ScienceDirect Snapshot:/Users/lxguo/Zotero/storage/PX93GUQF/S0010945211001018.html:text/html},
}

@article{pulvermuller_brain_2005,
	title = {Brain mechanisms linking language and action},
	volume = {6},
	copyright = {2005 Springer Nature Limited},
	issn = {1471-0048},
	url = {},
	doi = {},
	abstract = {For a long time the cortical systems for language and actions were believed to be independent modules. However, as these systems are reciprocally connected with each other, information about language and actions might interact in distributed neuronal assemblies. A critical case is that of action words that are semantically related to different parts of the body (for example, 'lick', 'pick' and 'kick'): does the comprehension of these words specifically, rapidly and automatically activate the motor system in a somatotopic manner, and does their comprehension rely on activity in the action system?},
	language = {en},
	number = {7},
	urldate = {2025-03-29},
	journal = {Nat Rev Neurosci},
	author = {Pulvermüller, Friedemann},
	month = jul,
	year = {2005},
	note = {},
	keywords = {Animal Genetics and Genomics, Behavioral Sciences, Biological Techniques, Biomedicine, general, Neurobiology, Neurosciences},
	pages = {576--582},
}


@article{huth_natural_2016,
	title = {Natural speech reveals the semantic maps that tile human cerebral cortex},
	volume = {532},
	copyright = {2016 Springer Nature Limited},
	issn = {1476-4687},
	url = {},
	doi = {},
	abstract = {The meaning of language is represented in regions of the cerebral cortex collectively known as the ‘semantic system’. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. Here we systematically map semantic selectivity across the cortex using voxel-wise modelling of functional MRI (fMRI) data collected while subjects listened to hours of narrative stories. We show that the semantic system is organized into intricate patterns that seem to be consistent across individuals. We then use a novel generative model to create a detailed semantic atlas. Our results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and our atlas shows which domains are represented in each area. This study demonstrates that data-driven methods—commonplace in studies of human neuroanatomy and functional connectivity—provide a powerful and efficient means for mapping functional representations in the brain.},
	language = {en},
	number = {7600},
	urldate = {2024-05-01},
	journal = {Nature},
	author = {Huth, Alexander G. and de Heer, Wendy A. and Griffiths, Thomas L. and Theunissen, Frédéric E. and Gallant, Jack L.},
	month = apr,
	year = {2016},
	note = {},
	keywords = {Language, Neural encoding},
	pages = {453--458},
	file = {Full Text PDF:/Users/lxguo/Zotero/storage/2E5L3NF3/Huth et al. - 2016 - Natural speech reveals the semantic maps that tile.pdf:application/pdf},
}


@article{ralph_neural_2017,
	title = {The neural and computational bases of semantic cognition},
	volume = {18},
	copyright = {2016 Springer Nature Limited},
	issn = {1471-0048},
	abstract = {Semantic cognition refers to our ability to use, manipulate and generalize knowledge that is acquired over the lifespan to support innumerable verbal and non-verbal behaviours.Semantic cognition relies on two principal interacting neural systems: representation and control. We refer to this two-system view as the controlled semantic cognition framework.Coherent, generalizable concepts are formed through the hub-and-spoke representational system with the hub localised to the anterior temporal region (bilaterally) and spokes localised in modality-specific association cortices that are distributed across the cortex.Convergent clinical and cognitive neuroscience data show that the anterior temporal lobe hub has graded variations of semantic function that follow its pattern of connectivity.Category-specific differences in semantic function reflect the contributions of different parts of the connectivity-constrained version of the hub-and-spoke framework.Semantic control is implemented within a distributed frontal and temporoparietal neural network. Semantic control supports executive mechanisms that constrain how activation propagates through the network for semantic representation.},
	language = {en},
	number = {1},
	urldate = {2024-03-19},
	journal = {Nat Rev Neurosci},
	author = {Ralph, Matthew A. Lambon and Jefferies, Elizabeth and Patterson, Karalyn and Rogers, Timothy T.},
	year = {2017},
	keywords = {Cognitive neuroscience, Dementia, Stroke},
	pages = {42--55},
	file = {41583_2017_BFnrn2016150_MOESM430_ESM.pdf:E\:\\Zotero\\Personal\\storage\\EAX9GNQE\\41583_2017_BFnrn2016150_MOESM430_ESM.pdf:application/pdf;Full Text PDF:E\:\\Zotero\\Personal\\storage\\GT85K9UP\\Ralph et al. - 2017 - The neural and computational bases of semantic cog.pdf:application/pdf},
}

@inproceedings{selvaraju_grad-cam_2017,
	title = {Grad-{CAM}: {Visual} {Explanations} {From} {Deep} {Networks} via {Gradient}-{Based} {Localization}},
	shorttitle = {Grad-{CAM}},
	urldate = {2024-05-24},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	year = {2017},
	pages = {618--626},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\D2ULZEHM\\Selvaraju et al. - 2017 - Grad-CAM Visual Explanations From Deep Networks v.pdf:application/pdf},
}

@article{fernandino_decoding_2022,
	title = {Decoding the information structure underlying the neural representation of concepts},
	volume = {119},
	abstract = {The nature of the representational code underlying conceptual knowledge remains a major unsolved problem in cognitive neuroscience. We assessed the extent to which different representational systems contribute to the instantiation of lexical concepts in high-level, heteromodal cortical areas previously associated with semantic cognition. We found that lexical semantic information can be reliably decoded from a wide range of heteromodal cortical areas in the frontal, parietal, and temporal cortex. In most of these areas, we found a striking advantage for experience-based representational structures (i.e., encoding information about sensory-motor, affective, and other features of phenomenal experience), with little evidence for independent taxonomic or distributional organization. These results were found independently for object and event concepts. Our findings indicate that concept representations in the heteromodal cortex are based, at least in part, on experiential information. They also reveal that, in most heteromodal areas, event concepts have more heterogeneous representations (i.e., they are more easily decodable) than object concepts and that other areas beyond the traditional “semantic hubs” contribute to semantic cognition, particularly the posterior cingulate gyrus and the precuneus.},
	language = {en-US},
	number = {6},
	urldate = {2024-11-16},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fernandino, Leonardo and Tong, Jia-Qing and Conant, Lisa L. and Humphries, Colin J. and Binder, Jeffrey R.},
	year = {2022},
	pages = {e2108091119},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\6DDERRZZ\\Fernandino et al. - 2022 - Decoding the information structure underlying the neural representation of concepts.pdf:application/pdf;pnas.2108091119.sapp:E\:\\Zotero\\Personal\\storage\\C5G9YY7M\\pnas.2108091119.sapp.pdf:application/pdf},
}

@article{binder_toward_2016,
	title = {Toward a brain-based componential semantic representation},
	volume = {33},
	issn = {0264-3294},
	abstract = {Componential theories of lexical semantics assume that concepts can be represented by sets of features or attributes that are in some sense primitive or basic components of meaning. The binary features used in classical category and prototype theories are problematic in that these features are themselves complex concepts, leaving open the question of what constitutes a primitive feature. The present availability of brain imaging tools has enhanced interest in how concepts are represented in brains, and accumulating evidence supports the claim that these representations are at least partly “embodied” in the perception, action, and other modal neural systems through which concepts are experienced. In this study we explore the possibility of devising a componential model of semantic representation based entirely on such functional divisions in the human brain. We propose a basic set of approximately 65 experiential attributes based on neurobiological considerations, comprising sensory, motor, spatial, temporal, affective, social, and cognitive experiences. We provide normative data on the salience of each attribute for a large set of English nouns, verbs, and adjectives, and show how these attribute vectors distinguish a priori conceptual categories and capture semantic similarity. Robust quantitative differences between concrete object categories were observed across a large number of attribute dimensions. A within- versus between-category similarity metric showed much greater separation between categories than representations derived from distributional (latent semantic) analysis of text. Cluster analyses were used to explore the similarity structure in the data independent of a priori labels, revealing several novel category distinctions. We discuss how such a representation might deal with various longstanding problems in semantic theory, such as feature selection and weighting, representation of abstract concepts, effects of context on semantic retrieval, and conceptual combination. In contrast to componential models based on verbal features, the proposed representation systematically relates semantic content to large-scale brain networks and biologically plausible accounts of concept acquisition.},
	number = {3-4},
	urldate = {2024-11-16},
	journal = {Cognitive Neuropsychology},
	author = {Binder, Jeffrey R. and Conant, Lisa L. and Humphries, Colin J. and Fernandino, Leonardo and Simons, Stephen B. and Aguilar, Mario and Desai, Rutvik H.},
	year = {2016},
	keywords = {cognitive neuroscience, concept representation, embodied cognition, Semantics},
	pages = {130--174},
	file = {PDF:E\:\\Zotero\\Personal\\storage\\TNKS33YR\\Binder et al. - 2016 - Toward a brain-based componential semantic representation.pdf:application/pdf},
}

@article{giallanza_integrated_2024,
	title = {An integrated model of semantics and control},
	issn = {1939-1471},
	abstract = {Understanding the mechanisms enabling the learning and flexible use of knowledge in context-appropriate ways has been a major focus of research in the study of both semantic cognition and cognitive control. We present a unified model of semantics and control that addresses these questions from both perspectives. The model provides a coherent view of how semantic knowledge, and the ability to flexibly access and deploy that knowledge to meet current task demands, arises from end-to-end learning of the statistics of the environment. We show that the model addresses unresolved issues from both literatures, including how control operates over features that covary with one another and how control representations themselves are structured and emerge through learning, through a series of behavioral experiments and simulations. We conclude by discussing the implications of our approach to other fundamental questions in cognitive science, machine learning, and artificial intelligence. (PsycInfo Database Record (c) 2024 APA, all rights reserved)},
	language = {en-US},
	journal = {Psychological Review},
	author = {Giallanza, Tyler and Campbell, Declan and Cohen, Jonathan D. and Rogers, Timothy T.},
	year = {2024},
	keywords = {Cognitive Control, Cognitive Processes, Learning, Models, Semantics},
	pages = {No Pagination Specified--No Pagination Specified},
	file = {Giallanza et al. - 2023 - An integrated model of semantics and control:E\:\\Zotero\\Personal\\storage\\SQZG4DAU\\Giallanza et al. - 2023 - An integrated model of semantics and control.pdf:application/pdf;Snapshot:E\:\\Zotero\\Personal\\storage\\AYQR7AJS\\2025-06326-001.html:text/html;Submitted Version:E\:\\Zotero\\Personal\\storage\\SGLEHD7T\\Giallanza et al. - 2024 - An integrated model of semantics and control.pdf:application/pdf},
}

@article{lupyan_categorization_2012,
	title = {Categorization is modulated by transcranial direct current stimulation over left prefrontal cortex},
	volume = {124},
	issn = {0010-0277},
	abstract = {Humans have an unparalleled ability to represent objects as members of multiple categories. A given object, such as a pillow may be—depending on current task demands—represented as an instance of something that is soft, as something that contains feathers, as something that is found in bedrooms, or something that is larger than a toaster. This type of processing requires the individual to dynamically highlight task-relevant properties and abstract over or suppress object properties that, although salient, are not relevant to the task at hand. Neuroimaging and neuropsychological evidence suggests that this ability may depend on cognitive control processes associated with the left inferior prefrontal gyrus. Here, we show that stimulating the left inferior frontal cortex using transcranial direct current stimulation alters performance of healthy subjects on a simple categorization task. Our task required subjects to select pictures matching a description, e.g., “click on all the round things.” Cathodal stimulation led to poorer performance on classification trials requiring attention to specific dimensions such as color or shape as opposed to trials that required selecting items belonging to a more thematic category such as objects that hold water. A polarity reversal (anodal stimulation) lowered the threshold for selecting items that were more weakly associated with the target category. These results illustrate the role of frontally-mediated control processes in categorization and suggest potential interactions between categorization, cognitive control, and language.},
	language = {en-US},
	number = {1},
	urldate = {2025-01-08},
	journal = {Cognition},
	author = {Lupyan, Gary and Mirman, Daniel and Hamilton, Roy and Thompson-Schill, Sharon L.},
	year = {2012},
	keywords = {Categorization, Classification, Cognitive control, Language, LIFG, tDCS},
	pages = {36--49},
	file = {PDF:E\:\\Zotero\\Personal\\storage\\Q8F6NTBJ\\Lupyan et al. - 2012 - Categorization is modulated by transcranial direct current stimulation over left prefrontal cortex.pdf:application/pdf;ScienceDirect Snapshot:E\:\\Zotero\\Personal\\storage\\ELG758F4\\S0010027712000741.html:text/html},
}

@article{cohen_control_1990,
	title = {On the control of automatic processes: {A} parallel distributed processing account of the {Stroop} effect},
	volume = {97},
	issn = {1939-1471},
	shorttitle = {On the control of automatic processes},
	abstract = {Traditional views of automaticity are in need of revision. Recent empirical data suggest that automatic processes are continuous and subject to attentional control. A model of attention is presented. Within a parallel distributed processing framework, it is proposed that the attributes of automaticity depend on the strength of a processing pathway that strength increases with training. With the Stroop effect as an example, automatic processes are shown to be continuous and to emerge gradually with practice. Specifically, a computational model of the Stroop task simulates the time course of processing as well as the effects of learning. This was accomplished by combining the cascade mechanism described by J. L. McClelland (see record 1979-32860-001) with the backpropagation learning algorithm (D. E. Rumelhart et al, 1986). The model can simulate performance in the standard Stroop task, as well as aspects of performance in variants of this task that manipulate stimulus-onset asynchrony, response set, and degree of practice. This model is contrasted against other models, and its relation to many of the central issues in the literature on attention, automaticity, and inference is discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	language = {en-US},
	number = {3},
	journal = {Psychological Review},
	author = {Cohen, Jonathan D. and Dunbar, Kevin and McClelland, James L.},
	year = {1990},
	keywords = {Attention, Cognitive Processes, Models, Stroop Effect},
	pages = {332--361},
	file = {Snapshot:E\:\\Zotero\\Personal\\storage\\ZH5QSWYW\\1990-27437-001.html:text/html},
}

@book{rogers_semantic_2004,
	address = {Cambridge, MA, USA},
	title = {Semantic {Cognition}: {A} {Parallel} {Distributed} {Processing} {Approach}},
	isbn = {978-0-262-18239-3},
	shorttitle = {Semantic {Cognition}},
	abstract = {This groundbreaking monograph offers a mechanistic theory of the representation and use of semantic knowledge, integrating the strengths and overcoming many of the weaknesses of hierarchical, categorisation-based approaches, similarity-based approaches, and the approach often called theory theory. Building on earlier models by Geoff Hinton in the 1980s and David Rumelhart in the early 1990s, the authors propose that performance in semantic tasks arises through the propagation of graded signals in a system of interconnected processing units. The representations used in performing these tasks are patterns of activation across units, governed by weighted connections among them. Semantic knowledge is acquired through the gradual adjustment of the strengths of these connections in the course of day-to-day experience. The authors show how a simple computational model proposed by Rumelhart exhibits a progressive differentiation of conceptual knowledge, paralleling aspects of cognitive development seen in the work of Frank Keil and Jean Mandler. The authors extend the model to address aspects of conceptual knowledge acquisition in infancy, basic-level effects and their interaction with},
	language = {en},
	publisher = {MIT Press},
	author = {Rogers, Timothy T. and McClelland, James L.},
	year = {2004},
	keywords = {Computers / General, Computers / Parallel Processing, Medical / Neurology, Psychology / Cognitive Psychology \& Cognition, Psychology / General},
}

@article{martin_grapesgrounding_2016,
	title = {{GRAPES}—{Grounding} representations in action, perception, and emotion systems: {How} object properties and categories are represented in the human brain},
	volume = {23},
	issn = {1531-5320},
	shorttitle = {{GRAPES}—{Grounding} representations in action, perception, and emotion systems},
	abstract = {In this article, I discuss some of the latest functional neuroimaging findings on the organization of object concepts in the human brain. I argue that these data provide strong support for viewing concepts as the products of highly interactive neural circuits grounded in the action, perception, and emotion systems. The nodes of these circuits are defined by regions representing specific object properties (e.g., form, color, and motion) and thus are property-specific, rather than strictly modality-specific. How these circuits are modified by external and internal environmental demands, the distinction between representational content and format, and the grounding of abstract social concepts are also discussed.},
	language = {en},
	number = {4},
	urldate = {2025-01-19},
	journal = {Psychon Bull Rev},
	author = {Martin, Alex},
	year = {2016},
	keywords = {Cognitive neuroscience of memory, Concepts and categories, Embodied cognition, Neuroimaging and memory},
	pages = {979--990},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\L5PTGBKH\\Martin - 2016 - GRAPES—Grounding representations in action, perception, and emotion systems How object properties a.pdf:application/pdf},
}

@article{barsalou_perceptions_1999,
	title = {Perceptions of perceptual symbols},
	volume = {22},
	issn = {1469-1825, 0140-525X},
	abstract = {Various defenses of amodal symbol systems are addressed, 
including amodal symbols in sensory-motor areas, the causal theory 
of concepts, supramodal concepts, latent semantic analysis, and 
abstracted amodal symbols. Various aspects of perceptual symbol 
systems are clarified and developed, including perception, features,
 simulators, category structure, frames, analogy, introspection, 
situated action, and development. Particular attention is given 
to abstract concepts, language, and computational mechanisms.},
	language = {en},
	number = {4},
	urldate = {2025-01-19},
	journal = {Behavioral and Brain Sciences},
	author = {Barsalou, Lawrence W.},
	year = {1999},
	pages = {637--660},
}

@article{barsalou_grounded_2008,
	title = {Grounded {Cognition}},
	volume = {59},
	issn = {0066-4308, 1545-2085},
	abstract = {Grounded cognition rejects traditional views that cognition is computation on amodal symbols in a modular system, independent of the brain\&apos;s modal systems for perception, action, and introspection. Instead, grounded cognition proposes that modal simulations, bodily states, and situated action underlie cognition. Accumulating behavioral and neural evidence supporting this view is reviewed from research on perception, memory, knowledge, language, thought, social cognition, and development. Theories of grounded cognition are also reviewed, as are origins of the area and common misperceptions of it. Theoretical, empirical, and methodological issues are raised whose future treatment is likely to affect the growth and impact of grounded cognition.},
	language = {en},
	number = {Volume 59, 2008},
	urldate = {2025-01-19},
	journal = {Annual Review of Psychology},
	author = {Barsalou, Lawrence W.},
	year = {2008},
	pages = {617--645},
	file = {Snapshot:E\:\\Zotero\\Personal\\storage\\66GYZMEV\\annurev.psych.59.103006.html:text/html},
}

@article{jefferies_neural_2013,
	title = {The neural basis of semantic cognition: {Converging} evidence from neuropsychology, neuroimaging and {TMS}},
	volume = {49},
	issn = {0010-9452},
	shorttitle = {The neural basis of semantic cognition},
	abstract = {Recent studies suggest that a complex, distributed neural network underpins semantic cognition. This article reviews our contribution to this emerging picture and traces the putative roles of each region within this network. Neuropsychological studies indicate that semantic cognition draws on at least two interacting components: semantic representations [degraded in semantic dementia (SD)] and control processes [deficient in patients with multimodal semantic impairment following stroke aphasia (SA)]. To explore the first component, we employed distortion-corrected functional magnetic resonance imaging (fMRI) and transcranial magnetic stimulation (TMS) in healthy volunteers: these studies convergently indicated that the anterior temporal lobes (ATLs; atrophied in SD) combine information from different modalities within an amodal semantic “hub”. Regions of cortex that code specific semantic features (“spokes”) also make a critical contribution to knowledge within particular categories. This network of brain regions interacts with semantic control processes reliant on left inferior frontal gyrus (LIFG), posterior middle temporal gyrus (pMTG) and inferior parietal cortices. SA patients with damage to these regions have difficulty focussing on aspects of knowledge that are relevant to the current goal or context, in both verbal and non-verbal tasks. SA patients with LIFG and temporoparietal lesions show similar deficits of semantic control, suggesting that a large-scale distributed cortical network underpins semantic control. Convergent evidence is again provided by fMRI and TMS. We separately manipulated the representational and control demands of a semantic task in fMRI, and found a dissociation within the temporal lobe: ATL was sensitive to the number of meanings retrieved, while pMTG and LIFG showed effects of semantic selection. Moreover, TMS to LIFG and pMTG produced equal disruption of tasks tapping semantic control. The next challenges are to delineate the specific roles of each region within the semantic control network and to specify the way in which control processes interact with semantic representations to focus processing on relevant features of concepts.},
	number = {3},
	urldate = {2025-01-19},
	journal = {Cortex},
	author = {Jefferies, Elizabeth},
	year = {2013},
	keywords = {Aphasia, fMRI, Neuropsychology, Semantic cognition, Semantic dementia, Transcranial magnetic stimulation},
	pages = {611--625},
	file = {ScienceDirect Snapshot:E\:\\Zotero\\Personal\\storage\\WMJR67BJ\\S0010945212003103.html:text/html},
}

@article{jefferies_semantic_2006,
	title = {Semantic impairment in stroke aphasia versus semantic dementia: a case-series comparison},
	volume = {129},
	issn = {0006-8950},
	shorttitle = {Semantic impairment in stroke aphasia versus semantic dementia},
	abstract = {Different neuropsychological populations implicate diverse cortical regions in semantic memory: semantic dementia (SD) is characterized by atrophy of the anterior temporal lobes whilst poor comprehension in stroke aphasia is associated with prefrontal or temporal–parietal infarcts. This study employed a case-series design to compare SD and comprehension-impaired stroke aphasic patients directly on the same battery of semantic tests. Although the two groups obtained broadly equivalent scores, they showed qualitatively different semantic deficits. The SD group showed strong correlations between different semantic tasks—regardless of input/output modality—and substantial consistency when a set of items was assessed several times. They were also highly sensitive to frequency/familiarity and made coordinate and superordinate semantic errors in picture naming. These findings support the notion that amodal semantic representations degrade in SD. The stroke aphasia group also showed multimodal deficits and consistency across different input modalities, but inconsistent performance on tasks requiring different types of semantic processing. They were insensitive to familiarity/frequency—instead, tests of semantic association were influenced by the ease with which relevant semantic relationships could be identified and distractors rejected. In addition, the aphasic patients made associative semantic errors in picture naming that SD patients did not make. The aphasic patients' picture naming performance improved considerably with phonemic cues suggesting that these patients retained knowledge that could not be accessed without contextual support. We propose that semantic cognition is supported by two interacting principal components: (i) a set of amodal representations (which progressively degrade in SD) and (ii) executive processes that help to direct and control semantic activation in a task-appropriate fashion (which are dysfunctional in comprehension-impaired stroke aphasic patients).},
	number = {8},
	urldate = {2025-01-19},
	journal = {Brain},
	author = {Jefferies, Elizabeth and Lambon Ralph, Matthew A.},
	year = {2006},
	pages = {2132--2147},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\EPVUW7MY\\Jefferies and Lambon Ralph - 2006 - Semantic impairment in stroke aphasia versus semantic dementia a case-series comparison.pdf:application/pdf;Snapshot:E\:\\Zotero\\Personal\\storage\\WJ9G8D4A\\333526.html:text/html},
}

@article{badre_left_2007,
	title = {Left ventrolateral prefrontal cortex and the cognitive control of memory},
	volume = {45},
	issn = {0028-3932},
	abstract = {Cognitive control mechanisms permit memory to be accessed strategically, and so aid in bringing knowledge to mind that is relevant to current goals and actions. In this review, we consider the contribution of left ventrolateral prefrontal cortex (VLPFC) to the cognitive control of memory. Reviewed evidence supports a two-process model of mnemonic control, supported by a double dissociation among rostral regions of left VLPFC. Specifically, anterior VLPFC (∼BA 47; inferior frontal gyrus pars orbitalis) supports controlled access to stored conceptual representations, whereas mid-VLPFC (∼BA 45; inferior frontal gyrus pars triangularis) supports a domain-general selection process that operates post-retrieval to resolve competition among active representations. We discuss the contribution of these control mechanisms across a range of mnemonic domains, including semantic retrieval, recollection of contextual details about past events, resolution of proactive interference in working memory, and task switching. Finally, we consider open directions for future research into left VLPFC function and the cognitive control of memory.},
	number = {13},
	urldate = {2025-01-19},
	journal = {Neuropsychologia},
	author = {Badre, David and Wagner, Anthony D.},
	year = {2007},
	keywords = {Cognitive control, Executive function, Memory, Prefrontal cortex},
	pages = {2883--2901},
	file = {ScienceDirect Snapshot:E\:\\Zotero\\Personal\\storage\\3VHLQRK9\\S0028393207002217.html:text/html},
}

@inproceedings{bastian_gephi_2009,
	title = {Gephi: {An} {Open} {Source} {Software} for {Exploring} and {Manipulating} {Networks}},
	volume = {3},
	copyright = {Copyright (c) 2021 Proceedings of the International AAAI Conference on Web and Social Media},
	shorttitle = {Gephi},
	abstract = {Gephi is an open source software for graph and network analysis. It uses a 3D render engine to display large networks in real-time and to speed up the exploration. A flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results.  We present several key features of Gephi in the context of interactive exploration and interpretation of networks. It provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. Finally, by presenting dynamic features of Gephi, we highlight key aspects of dynamic network visualization.},
	language = {en},
	urldate = {2025-01-19},
	booktitle = {Proceedings of the {International} {AAAI} {Conference} on {Web} and {Social} {Media}},
	author = {Bastian, Mathieu and Heymann, Sebastien and Jacomy, Mathieu},
	year = {2009},
	keywords = {webatlas},
	pages = {361--362},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\VPZ3XYIQ\\Bastian et al. - 2009 - Gephi An Open Source Software for Exploring and Manipulating Networks.pdf:application/pdf},
}

@inproceedings{mikolov_distributed_2013,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	volume = {26},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships.  In this paper we present several improvements that make the Skip-gram model more expressive and enable it to learn higher quality vectors more rapidly.  We show that by subsampling frequent words we obtain significant speedup,  and also learn higher quality representations as measured by our tasks. We also introduce Negative Sampling, a simplified variant of Noise Contrastive Estimation (NCE) that learns more accurate vectors for frequent words compared to the hierarchical softmax.   An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases.  For example, the meanings of Canada'' and "Air'' cannot be easily combined to obtain "Air Canada''.  Motivated by this example, we present a simple and efficient method for finding phrases, and show that their vector representations can be accurately learned by the Skip-gram model. "},
	urldate = {2025-01-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	year = {2013},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\B7Y5KXRG\\Mikolov et al. - 2013 - Distributed Representations of Words and Phrases and their Compositionality.pdf:application/pdf},
}

@inproceedings{mikolov_advances_2018,
	title = {Advances in {Pre}-{Training} {Distributed} {Word} {Representations}},
	isbn = {979-10-95546-00-9},
	abstract = {Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.},
	language = {en},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation}},
	author = {Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
	year = {2018},
	file = {PDF:E\:\\Zotero\\Personal\\storage\\FKS7LWAG\\Mikolov et al. - Advances in Pre-Training Distributed Word Representations.pdf:application/pdf},
}

@article{jackson_neural_2021,
	title = {The neural correlates of semantic control revisited},
	volume = {224},
	issn = {1053-8119},
	abstract = {Semantic control, the ability to selectively access and manipulate meaningful information on the basis of context demands, is a critical component of semantic cognition. The precise neural correlates of semantic control are disputed, with particular debate surrounding parietal involvement, the spatial extent of the posterior temporal contribution and network lateralisation. Here semantic control is revisited, utilising improved analysis techniques and a decade of additional data to refine our understanding of the network. A meta-analysis of 925 peaks over 126 contrasts illuminated a left-focused network consisting of inferior frontal gyrus, posterior middle temporal gyrus, posterior inferior temporal gyrus and dorsomedial prefrontal cortex. This extended the temporal region implicated, and found no parietal involvement. Although left-lateralised overall, relative lateralisation varied across the implicated regions. Supporting analyses confirmed the multimodal nature of the semantic control network and situated it within the wider set of regions implicated in semantic cognition.},
	language = {en-US},
	urldate = {2025-01-19},
	journal = {NeuroImage},
	author = {Jackson, Rebecca L.},
	year = {2021},
	keywords = {ALE meta-analysis, Control, Executive processing, Semantic cognition, Semantic control},
	pages = {117444},
	file = {Accepted Version:E\:\\Zotero\\Personal\\storage\\LMRQQRSA\\Jackson - 2021 - The neural correlates of semantic control revisited.pdf:application/pdf},
}

@article{wieczorek_framework_2024,
	title = {A framework for the emergence and analysis of language in social learning agents},
	volume = {15},
	copyright = {2024 The Author(s)},
	issn = {2041-1723},
	abstract = {Neural systems have evolved not only to solve environmental challenges through internal representations but also, under social constraints, to communicate these to conspecifics. In this work, we aim to understand the structure of these internal representations and how they may be optimized to transmit pertinent information from one individual to another. Thus, we build on previous teacher-student communication protocols to analyze the formation of individual and shared abstractions and their impact on task performance. We use reinforcement learning in grid-world mazes where a teacher network passes a message to a student to improve task performance. This framework allows us to relate environmental variables with individual and shared representations. We compress high-dimensional task information within a low-dimensional representational space to mimic natural language features. In coherence with previous results, we find that providing teacher information to the student leads to a higher task completion rate and an ability to generalize tasks it has not seen before. Further, optimizing message content to maximize student reward improves information encoding, suggesting that an accurate representation in the space of messages requires bi-directional input. These results highlight the role of language as a common representation among agents and its implications on generalization capabilities.},
	language = {en},
	number = {1},
	urldate = {2024-09-14},
	journal = {Nat Commun},
	author = {Wieczorek, Tobias J. and Tchumatchenko, Tatjana and Wert-Carvajal, Carlos and Eggl, Maximilian F.},
	month = aug,
	year = {2024},
	note = {},
	keywords = {Learning algorithms, Neural decoding},
	pages = {7590},
	file = {41467_2024_51887_MOESM1_ESM:E\:\\Zotero\\Personal\\storage\\5NI4Z6GR\\41467_2024_51887_MOESM1_ESM.pdf:application/pdf;Full Text PDF:E\:\\Zotero\\Personal\\storage\\H9MUYCYR\\Wieczorek et al. - 2024 - A framework for the emergence and analysis of lang.pdf:application/pdf},
}


@article{wang_emergence_2024,
	title = {Emergence of machine language: towards symbolic intelligence with neural networks},
	volume = {11},
	issn = {2095-5138},
	shorttitle = {Emergence of machine language},
	abstract = {Representation learning is a core issue in artificial intelligence (AI). Currently, there exists a disparity in the choice of representation between humans and machines. Humans rely on discrete language for communication and learning, whereas machines utilize continuous features for computation and representation. Discrete symbols are low-dimensional, decoupled and offer robust reasoning abilities, while continuous features are high-dimensional, coupled and possess remarkable abstracting capabilities. In recent years, deep learning [1] has developed the idea of continuous representation to the extreme, using billions of parameters to achieve high accuracies. Although this is reasonable from a statistical perspective, it has other major problems, such as a lack of interpretability, poor generalization and being easily attacked. Both paradigms have strengths and weaknesses, and a better choice is to seek reconciliation.},
	language = {en-US},
	number = {4},
	urldate = {2024-04-19},
	journal = {National Science Review},
	author = {Wang, Yuqi and Zhang, Xu-Yao and Liu, Cheng-Lin and Tan, Tieniu and Zhang, Zhaoxiang},
	month = apr,
	year = {2024},
	pages = {nwad317},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\CWEQHHAF\\Wang et al. - 2024 - Emergence of machine language towards symbolic in.pdf:application/pdf;nwad317_supplemental_file.pdf:E\:\\Zotero\\Personal\\storage\\TP3II7PN\\nwad317_supplemental_file.pdf:application/pdf;Snapshot:E\:\\Zotero\\Personal\\storage\\4D2CXJ4V\\7505147.html:text/html},
}

@inproceedings{jaques_social_2019,
	title = {Social {Influence} as {Intrinsic} {Motivation} for {Multi}-{Agent} {Deep} {Reinforcement} {Learning}},
	abstract = {We propose a unified mechanism for achieving coordination and communication in Multi-Agent Reinforcement Learning (MARL), through rewarding agents for having causal influence over other agents’ actions. Causal influence is assessed using counterfactual reasoning. At each timestep, an agent simulates alternate actions that it could have taken, and computes their effect on the behavior of other agents. Actions that lead to bigger changes in other agents’ behavior are considered influential and are rewarded. We show that this is equivalent to rewarding agents for having high mutual information between their actions. Empirical results demonstrate that influence leads to enhanced coordination and communication in challenging social dilemma environments, dramatically increasing the learning curves of the deep RL agents, and leading to more meaningful learned communication protocols. The influence rewards for all agents can be computed in a decentralized way by enabling agents to learn a model of other agents using deep neural networks. In contrast, key previous works on emergent communication in the MARL setting were unable to learn diverse policies in a decentralized manner and had to resort to centralized training. Consequently, the influence reward opens up a window of new opportunities for research in this area.},
	language = {en},
	urldate = {2025-03-20},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {},
	author = {Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, Dj and Leibo, Joel Z. and Freitas, Nando De},
	month = may,
	year = {2019},
	note = {},
	pages = {3040--3049},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\7SIL4XGX\\Jaques et al. - 2019 - Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning.pdf:application/pdf;Supplementary PDF:E\:\\Zotero\\Personal\\storage\\QD5PGTSW\\Jaques et al. - 2019 - Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning.pdf:application/pdf},
}


@inproceedings{foerster_learning_2016,
	title = {Learning to {Communicate} with {Deep} {Multi}-{Agent} {Reinforcement} {Learning}},
	volume = {29},
	abstract = {We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.},
	language = {en-US},
	urldate = {2025-03-10},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
	year = {2016},
	pages = {},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\P4Y23T49\\Foerster et al. - 2016 - Learning to Communicate with Deep Multi-Agent Reinforcement Learning.pdf:application/pdf},
}

@article{ungerleider_what_1994,
	title = {‘{What}’ and ‘where’ in the human brain},
	volume = {4},
	issn = {0959-4388},
	abstract = {Multiple visual areas in the cortex of nonhuman primates are organized into two hierarchically organized and functionally specialized processing pathways, a ‘ventral stream’ for object vision and a ‘dorsal stream’ for spatial vision. Recent findings from positron emission tomography activation studies have localized these pathways within the human brain, yielding insights into cortical hierarchies, specialization of function, and attentional mechanisms.},
	number = {2},
	urldate = {2025-05-08},
	journal = {Current Opinion in Neurobiology},
	author = {Ungerleider, Leslie G. and Haxby, James V.},
	month = jan,
	year = {1994},
	pages = {157--165},
	file = {ScienceDirect Snapshot:E\:\\Zotero\\Personal\\storage\\UZQ6E76W\\0959438894900663.html:text/html},
}

@article{fedorenko_broad_2013,
	title = {Broad domain generality in focal regions of frontal and parietal cortex},
	volume = {110},
	abstract = {Unlike brain regions that respond selectively to specific kinds of information content, a number of frontal and parietal regions are thought to be domain- and process-general: that is, active during a wide variety of demanding cognitive tasks. However, most previous evidence for this functional generality in humans comes from methods that overestimate activation overlap across tasks. Here we present functional MRI evidence from single-subject analyses for broad functional generality of a specific set of brain regions: the same sets of voxels are engaged across tasks ranging from arithmetic to storing information in working memory, to inhibiting irrelevant information. These regions have a specific topography, often lying directly adjacent to domain-specific regions. Thus, in addition to domain-specific brain regions tailored to solve particular problems of longstanding importance to our species, the human brain also contains a set of functionally general regions that plausibly endow us with the cognitive flexibility necessary to solve novel problems.},
	number = {41},
	urldate = {2025-01-19},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fedorenko, Evelina and Duncan, John and Kanwisher, Nancy},
	year = {2013},
	pages = {16616--16621},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\Y89DZT4Q\\Fedorenko et al. - 2013 - Broad domain generality in focal regions of frontal and parietal cortex.pdf:application/pdf},
}

@article{kriegeskorte_information-based_2006,
	title = {Information-based functional brain mapping},
	volume = {103},
	abstract = {The development of high-resolution neuroimaging and multielectrode electrophysiological recording provides neuroscientists with huge amounts of multivariate data. The complexity of the data creates a need for statistical summary, but the local averaging standardly applied to this end may obscure the effects of greatest neuroscientific interest. In neuroimaging, for example, brain mapping analysis has focused on the discovery of activation, i.e., of extended brain regions whose average activity changes across experimental conditions. Here we propose to ask a more general question of the data: Where in the brain does the activity pattern contain information about the experimental condition? To address this question, we propose scanning the imaged volume with a “searchlight,” whose contents are analyzed multivariately at each location in the brain.},
	number = {10},
	urldate = {2025-01-19},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kriegeskorte, Nikolaus and Goebel, Rainer and Bandettini, Peter},
	year = {2006},
	pages = {3863--3868},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\C7KJX6E9\\Kriegeskorte et al. - 2006 - Information-based functional brain mapping.pdf:application/pdf},
}

@inproceedings{deng_imagenet_2009,
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	shorttitle = {{ImageNet}},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	language = {en-US},
	urldate = {2025-01-19},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	year = {2009},
	keywords = {Explosions, Image databases, Image retrieval, Information retrieval, Internet, Large-scale systems, Multimedia databases, Ontologies, Robustness, Spine},
	pages = {248--255},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\XMBGF546\\Deng et al. - 2009 - ImageNet A large-scale hierarchical image database.pdf:application/pdf},
}


@techreport{krizhevsky_learning_2009,
	title = {Learning {Multiple} {Layers} of {Features} from {Tiny} {Images}},
	language = {en},
	institution = {University of Toronto},
	author = {Krizhevsky, Alex and Hinton, Geoffrey E.},
	year = {2009},
	file = {PDF:E\:\\Zotero\\Personal\\storage\\HHIMPDI2\\Krizhevsky - Learning Multiple Layers of Features from Tiny Images.pdf:application/pdf},
}

@article{harnad_symbol_1990,
	title = {The symbol grounding problem},
	volume = {42},
	issn = {0167-2789},
	abstract = {There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the “symbol grounding problem”: How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) iconic representations, which are analogs of the proximal sensory projections of distal objects and events, and (2) categorical representations, which are learned and innate feature detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) symbolic representations, grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g. “An X is a Y that is Z”). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic “module,” however; the symbolic functions would emerge as an intrinsically “dedicated” symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.},
	language = {en},
	number = {1},
	urldate = {2023-04-14},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Harnad, Stevan},
	month = jun,
	year = {1990},
	pages = {335--346},
}

@misc{deepseek-ai_deepseek-r1_2025,
	title = {{DeepSeek}-{R1}: {Incentivizing} {Reasoning} {Capability} in {LLMs} via {Reinforcement} {Learning}},
	shorttitle = {{DeepSeek}-{R1}},
	abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
	language = {en-US},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
	month = jan,
	year = {2025},
	note = {arXiv:2501.12948 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:E\:\\Zotero\\Personal\\storage\\XHMG2JSG\\DeepSeek-AI et al. - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.pdf:application/pdf;Snapshot:E\:\\Zotero\\Personal\\storage\\AT9ZTCER\\2501.html:text/html},
}

@inproceedings{he_deep_2016,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	urldate = {2025-01-19},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2016},
	pages = {770--778},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\IZ4R99UH\\He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@book{fellbaum_wordnet_1998,
	address = {Cambridge, MA, USA},
	title = {{WordNet}: {An} {Electronic} {Lexical} {Database}},
	isbn = {978-0-262-06197-1},
	shorttitle = {{WordNet}},
	abstract = {WordNet is an on-line lexical reference system whose design isinspired by current psycholinguistic theories of human lexical memory;version 1.6 is the most up-to-date version of the system.WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets.The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains. ContributorsReem Al-Halimi, Robert C. Berwick, J. F. M. Burg, Martin Chodorow, Christiane Fellbaum, Joachim Grabowski, Sanda Harabagiu, Marti A. Hearst, Graeme Hirst, Douglas A. Jones, Rick Kazman, Karen T. Kohl, Shari Landes, Claudia Leacock, George A. Miller, Katherine J. Miller, Dan Moldovan, Naoyuki Nomura, Uta Priss, Philip Resnik, David St-Onge, Randee Tengi, Reind P. van de Riet, Ellen Voorhees},
	language = {en},
	publisher = {MIT Press},
	author = {Fellbaum, Christiane},
	year = {1998},
	keywords = {Computers / Artificial Intelligence / General, Computers / Languages / General, Language Arts \& Disciplines / General, Language Arts \& Disciplines / Linguistics / General},
}

@misc{kingma_adam_2015,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2025-01-19},
	publisher = {},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2015},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Preprint PDF:E\:\\Zotero\\Personal\\storage\\232EW2ZN\\Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;Snapshot:E\:\\Zotero\\Personal\\storage\\577XXVSK\\1412.html:text/html},
}


@article{xia_brainnet_2013,
	title = {{BrainNet} {Viewer}: {A} {Network} {Visualization} {Tool} for {Human} {Brain} {Connectomics}},
	volume = {8},
	issn = {1932-6203},
	shorttitle = {{BrainNet} {Viewer}},
	abstract = {The human brain is a complex system whose topological organization can be represented using connectomics. Recent studies have shown that human connectomes can be constructed using various neuroimaging technologies and further characterized using sophisticated analytic strategies, such as graph theory. These methods reveal the intriguing topological architectures of human brain networks in healthy populations and explore the changes throughout normal development and aging and under various pathological conditions. However, given the huge complexity of this methodology, toolboxes for graph-based network visualization are still lacking. Here, using MATLAB with a graphical user interface (GUI), we developed a graph-theoretical network visualization toolbox, called BrainNet Viewer, to illustrate human connectomes as ball-and-stick models. Within this toolbox, several combinations of defined files with connectome information can be loaded to display different combinations of brain surface, nodes and edges. In addition, display properties, such as the color and size of network elements or the layout of the figure, can be adjusted within a comprehensive but easy-to-use settings panel. Moreover, BrainNet Viewer draws the brain surface, nodes and edges in sequence and displays brain networks in multiple views, as required by the user. The figure can be manipulated with certain interaction functions to display more detailed information. Furthermore, the figures can be exported as commonly used image file formats or demonstration video for further use. BrainNet Viewer helps researchers to visualize brain networks in an easy, flexible and quick manner, and this software is freely available on the NITRC website (www.nitrc.org/projects/bnv/).},
	language = {en},
	number = {7},
	urldate = {2025-05-20},
	journal = {PLOS ONE},
	author = {Xia, Mingrui and Wang, Jinhui and He, Yong},
	month = jul,
	year = {2013},
	note = {},
	keywords = {Brain, Brain mapping, Computer networks, Connectomics, Data visualization, Network analysis, Neural networks, Vision},
	pages = {e68910},
	file = {Full Text PDF:E\:\\Zotero\\Personal\\storage\\WQX5FS8L\\Xia et al. - 2013 - BrainNet Viewer A Network Visualization Tool for Human Brain Connectomics.pdf:application/pdf},
}
